{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build legacy storet database\n",
    "# Data accessed at https://www3.epa.gov/storet/legacy/gateway.htm\n",
    "#\n",
    "#result_file_list = glob.glob('C:/Users/thodson/Desktop/Projects/nrec/data/legacy_storet/Illinois/Illinois/*/*_res_*') \n",
    "#\n",
    "##build full database from legacy storet files\n",
    "#dtype = {\n",
    "#    'Start Time':str,\n",
    "#    'End Time': str,\n",
    "#    'Station': str,\n",
    "#    'Param': str,\n",
    "#    'HUC': str,\n",
    "#    'CS': str,\n",
    "#    'CM': str,\n",
    "#    'Primary Activity Category' : str,\n",
    "#    'Secondary Activity Category' : str\n",
    "#}\n",
    "#parse_dates = ['Start Date','End Date']\n",
    "#\n",
    "#for result_file in result_file_list:\n",
    "#    df = pd.read_csv(result_file,\n",
    "#                 sep='[ ]*\\t+[ ]*',\n",
    "#                 dtype=dtype,\n",
    "#                 parse_dates=parse_dates,\n",
    "#                 header=0, skiprows=[1])\n",
    "#    # drop all non-numeric results\n",
    "#    df['Result Value'] = pd.to_numeric(df['Result Value'], errors='coerce')\n",
    "#    df = df.dropna(subset=['Result Value', 'Start Date'])\n",
    "#    \n",
    "#    df.to_sql('legacy_storet',\n",
    "#              con=engine,\n",
    "#              schema='nrec',\n",
    "#              if_exists ='append')\n",
    "\n",
    "\n",
    "##df = pd.read_sql_table('legacy_storet',\n",
    "##                       con=engine,\n",
    "##                       schema='nrec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:Qwert213@localhost/postgres')\n",
    "\n",
    "project_name = 'ambient_2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Scroll down to crosswalk section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#0 load site info from excel table\n",
    "\n",
    "filename='../../data/ambient_sites_v2023.csv'\n",
    "sites = pd.read_csv(filename, dtype={'USGS Code':str, 'USGS Gage':str})\n",
    "\n",
    "storet_id = 'IL_EPA_WQX-' + sites['StationCode']\n",
    "\n",
    "usgs_sites = sites['USGS Code']\n",
    "#usgs_sites = usgs_sites[usgs_sites.values != 'nan'].values.tolist()\n",
    "usgs_sites = usgs_sites[~usgs_sites.isna()].values.tolist()\n",
    "\n",
    "usgs_gages = sites['USGS Gage']\n",
    "#usgs_sites = usgs_sites[usgs_sites.values != 'nan'].values.tolist()\n",
    "usgs_gages = usgs_gages[~usgs_gages.isna()].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start here XXX\n",
    "gage_rename = sites[['USGS Code','USGS Gage']].dropna()\n",
    "usgs_sites = gage_rename['USGS Code']\n",
    "usgs_gages = gage_rename['USGS Gage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_with_different_gages_index = gage_rename['USGS Code'] != gage_rename['USGS Gage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['05563800',\n",
       " '05568005',\n",
       " '05577505',\n",
       " '03346550',\n",
       " '03343395',\n",
       " '03381495',\n",
       " '05554490',\n",
       " '05599500',\n",
       " '05593010',\n",
       " '05546700',\n",
       " '05553000']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usgs_sites[sites_with_different_gages_index].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all samples associated with sites (where site number differs from gage number)\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}') AND \"Agency\" = '21ILAMB'\n",
    "\"\"\".format(project_name, \"','\".join(usgs_sites[sites_with_different_gages_index].to_list()))\n",
    "\n",
    "samples_by_usgs_site = pd.read_sql_query(query, engine)\n",
    "# move samples to gage\n",
    "\n",
    "samples_by_usgs_site = samples_by_usgs_site.merge(gage_rename, how='inner', right_on='USGS Code', left_on='Station') \n",
    "samples_by_usgs_site['Station'] = samples_by_usgs_site['USGS Gage']\n",
    "samples_by_usgs_site = samples_by_usgs_site.drop(['USGS Gage','USGS Code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123433, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_site.shape #123433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all samples by usgs gage ID\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}') AND \"Agency\" = '21ILAMB'\n",
    "\"\"\".format(project_name, \"','\".join(usgs_gages))\n",
    "\n",
    "samples_by_usgs_gage = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(894323, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_gage.shape #894323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#samples_by_usgs_gage = samples_by_usgs_gage.append(samples_by_usgs_site)\n",
    "samples_by_usgs_gage = pd.concat([samples_by_usgs_gage, samples_by_usgs_site])\n",
    "samples_by_usgs_gage = samples_by_usgs_gage.replace({'00940':'99220'})\n",
    "samples_by_usgs_gage.to_sql('legacy_storet_temp',\n",
    "            con=engine,\n",
    "            schema=project_name,\n",
    "            if_exists ='replace')\n",
    "#756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017756, 24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_gage.shape #1017756\n",
    "#append\n",
    "# drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thodson\\AppData\\Local\\Temp\\1\\ipykernel_113980\\4046451299.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  station_rename = station_rename.append(other_legacy_sites)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select mislabeld samples and append to legacy_storet_temp XXX\n",
    "station_rename = sites[['StationCode','USGS Gage']].dropna()\n",
    "station_rename['StationCode'] = station_rename['StationCode'].str.replace('-',' ')\n",
    "\n",
    "other_legacy_sites = [\n",
    "    ['DT      01', '05552500']\n",
    "]\n",
    "other_legacy_sites = pd.DataFrame(other_legacy_sites, columns=['StationCode','USGS Gage'])\n",
    "\n",
    "station_rename = station_rename.append(other_legacy_sites)\n",
    "\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}')\n",
    "\"\"\".format(project_name, \"','\".join(station_rename['StationCode'].to_list()))\n",
    "\n",
    "missing_samples = pd.read_sql_query(query, engine)\n",
    "missing_samples = missing_samples.replace({'00940':'99220'})\n",
    "# rename Stations to match USGS gages\n",
    "station_rename_dict = {row['StationCode']:row['USGS Gage'] for index, row in station_rename.iterrows()}\n",
    "missing_samples['Station'] = missing_samples['Station'].replace(station_rename_dict)\n",
    "\n",
    "missing_samples.to_sql('legacy_storet_temp',\n",
    "            con=engine,\n",
    "            schema=project_name,\n",
    "            if_exists ='append')\n",
    "\n",
    "#679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 24)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_samples.shape #1679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019435, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx = pd.read_sql_table('legacy_storet_temp',con=engine, schema='ambient_2023') # was nrec\n",
    "xxx.shape #was (1027031\n",
    "#1019435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753934   1965-01-12\n",
       "753935   1965-01-12\n",
       "753936   1965-01-12\n",
       "753937   1965-12-10\n",
       "753938   1965-12-10\n",
       "            ...    \n",
       "790976   1998-12-10\n",
       "790977   1998-12-10\n",
       "790978   1998-12-10\n",
       "790979   1998-12-10\n",
       "790990   1998-12-10\n",
       "Name: Start Date, Length: 13707, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify legacy_storet_temp\n",
    "test = xxx[xxx['Station'] == '03339000']['Start Date']\n",
    "test.values.sort()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ambient_2023'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00116', '00339', '00627', '00668', '01028', '00938', '01003',\n",
       "       '01008', '01029', '01052', '01043', '01053', '01068', '01078',\n",
       "       '01093', '01170', '32212', '32210', '32211', '32218', '32214',\n",
       "       '39032', '39076', '39062', '39064', '39065', '39067', '39070',\n",
       "       '39073', '39301', '39300', '39111', '39305', '39306', '39311',\n",
       "       '39310', '39316', '39315', '39320', '39330', '39321', '39327',\n",
       "       '39328', '39333', '39343', '39340', '39337', '39350', '39351',\n",
       "       '39359', '39356', '39393', '39370', '39380', '39383', '39390',\n",
       "       '39480', '39413', '39423', '39519', '39481', '39516', '39530',\n",
       "       '39600', '39701', '39570', '39700', '39630', '39640', '70322',\n",
       "       '46313', '39783', '71921', '81294', '77825', '81284', '81408',\n",
       "       '81403', '82088', '81410', '81757', '00027', '00010', '00020',\n",
       "       '00076', '00028', '00530', '00094', '00299', '00400', '00301',\n",
       "       '00410', '00535', '00630', '00612', '00619', '00625', '00610',\n",
       "       '00666', '00665', '00900', '00720', '00927', '00916', '00925',\n",
       "       '00915', '00935', '00929', '00930', '99220', '00937', '00945',\n",
       "       '01005', '01002', '00951', '01022', '01010', '01012', '01007',\n",
       "       '01020', '01025', '01027', '01035', '01030', '01034', '01037',\n",
       "       '01042', '01040', '01045', '01065', '01056', '01046', '01049',\n",
       "       '01051', '01055', '01067', '01075', '01077', '01082', '01080',\n",
       "       '01085', '31616', '01090', '01092', '01106', '01087', '01105',\n",
       "       '01147', '32730', '46570', '71900', '46489'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_samples['Param'].unique()\n",
    "#missing_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existing table\n",
    "with engine.connect() as con:\n",
    "    con.execute(f\"\"\"DROP TABLE {project_name}.legacy_storet_cleaned;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do the above for each parameter in parameter list and append\n",
    "#query = \"\"\"\n",
    "#SELECT site_no as \"Station\", sample_dt as \"Start Date\" FROM nrec.wrtds WHERE p{0} IS NOT NULL\n",
    "#AND site_no in ('{1}')\n",
    "#\"\"\".format(parameter,\n",
    "#           \"','\".join(usgs_sites))\n",
    "\n",
    "# list must contain entries in the cleaned qwdata table. Cleaning moves 631 to 630; 631 doesn't appear in my legacy\n",
    "param_list = ['00530','00535','00600','00610','00625','00630','00665','00666','00667', '00946', '80154','99220']\n",
    "#param_list = ['00665']\n",
    "\n",
    "for parameter in param_list:\n",
    "    # select samples wrtds where site_no is in list of usgs gages\n",
    "    #SELECT site_no as \"Station\", TO_TIMESTAMP(sample_dt, 'YYYY-MM-DD') AT TIME ZONE 'CST' as \"Start Date\" FROM nrec.wrtds WHERE p{0} IS NOT NULL \n",
    "    query = \"\"\"\n",
    "    SELECT site_no as \"Station\", TO_DATE(cast(sample_dt as TEXT), 'YYYY-MM-DD') as \"Start Date\" FROM {0}.wrtds WHERE p{1} IS NOT NULL    \n",
    "    AND site_no in ('{2}')\n",
    "    \"\"\".format(project_name, parameter,\n",
    "               \"','\".join(usgs_gages)) #20210628 changed from usgs_sites\n",
    "    \n",
    "    # select samples form legacy storet where station in list of \n",
    "    query2 = \"\"\"SELECT * FROM {0}.legacy_storet_temp WHERE \"Station\" in ('{1}')\n",
    "    AND \"Param\" in ('{2}') AND \"Agency\" = '21ILAMB'\n",
    "    \"\"\".format(project_name, \"','\".join(usgs_gages),\n",
    "               parameter)\n",
    "    \n",
    "    query3 = \"\"\"\n",
    "    SELECT * FROM ({}) as table1\n",
    "    WHERE (\"Station\",\"Start Date\")\n",
    "    NOT IN ({})\n",
    "    \"\"\".format(query2, query)\n",
    "    \n",
    "\n",
    "    df = pd.read_sql_query(query3, engine)\n",
    "    \n",
    "    #df.to_sql('legacy_storet_missing_test',\n",
    "    # append each parameter to list\n",
    "    df.to_sql('legacy_storet_cleaned',\n",
    "              con=engine,\n",
    "              schema=project_name,\n",
    "              if_exists='append')\n",
    "\n",
    "# check in pg admin\n",
    "# select \"Start Date\" FROM nrec.legacy_storet_missing_test_v2 WHERE \"Station\"='05568000' AND \"Param\"='00630' ORDER BY \"Start Date\" DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete temporary table\n",
    "with engine.connect() as con:\n",
    "    con.execute(f\"\"\"DROP TABLE {project_name}.legacy_storet_temp;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter = '00665'\n",
    "#\n",
    "#query = \"\"\"\n",
    "#    SELECT site_no as \"Station\", TO_DATE(cast(sample_dt as TEXT), 'YYYY-MM-DD') as \"Start Date\" FROM {0}.wrtds WHERE p{1} IS NOT NULL    \n",
    "#    AND site_no in ('03339000')\n",
    "#    \"\"\".format(project_name, parameter) #20210628 changed from usgs_sites\n",
    "#    \n",
    "#    # select samples form legacy storet where station in list of \n",
    "#query2 = \"\"\"SELECT * FROM {0}.legacy_storet_temp WHERE \"Station\" in ('03339000')\n",
    "#    AND \"Param\" in ('{1}') AND \"Agency\" = '21ILAMB'\n",
    "#    \"\"\".format(project_name, parameter)\n",
    "#    \n",
    "#query3 = \"\"\"\n",
    "#    SELECT * FROM ({}) as table1\n",
    "#    WHERE (\"Station\",\"Start Date\")\n",
    "#    NOT IN ({})\n",
    "#    \"\"\".format(query2, query)\n",
    "#    \n",
    "#\n",
    "#df = pd.read_sql_query(query3, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Station</th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Agency Name</th>\n",
       "      <th>State Name</th>\n",
       "      <th>County Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Result Value</th>\n",
       "      <th>...</th>\n",
       "      <th>End Date</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Sample Depth</th>\n",
       "      <th>UMK</th>\n",
       "      <th>Replicate Number</th>\n",
       "      <th>CS</th>\n",
       "      <th>COMPOSITE_GRAB_NUMBER</th>\n",
       "      <th>CM</th>\n",
       "      <th>Primary Activity Category</th>\n",
       "      <th>Secondary Activity Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, Agency, Station, Station Name, Agency Name, State Name, County Name, Latitude, Longitude, Result Value, R, HUC, Param, Start Date, Start Time, End Date, End Time, Sample Depth, UMK, Replicate Number, CS, COMPOSITE_GRAB_NUMBER, CM, Primary Activity Category, Secondary Activity Category]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Start Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>03339000</td>\n",
       "      <td>2022-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>03339000</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>03339000</td>\n",
       "      <td>2022-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>03339000</td>\n",
       "      <td>2022-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>03339000</td>\n",
       "      <td>2022-05-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Station  Start Date\n",
       "604  03339000  2022-02-22\n",
       "605  03339000  2022-03-07\n",
       "606  03339000  2022-03-30\n",
       "607  03339000  2022-03-31\n",
       "608  03339000  2022-05-06"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_sql_table(query, engine)\n",
    "test.tail()\n",
    "#x = test['Start Date'].values\n",
    "#x.sort()\n",
    "#x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('1978-04-11T00:00:00.000000000')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test = pd.read_sql_query(query2, engine)\n",
    "#out = test['Start Date'].values\n",
    "#out.sort()\n",
    "#out[0]\n",
    "##test[['Station','Start Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1977-12-29\n",
       "1        1978-03-28\n",
       "2        1978-04-12\n",
       "3        1978-05-18\n",
       "4        1978-06-01\n",
       "            ...    \n",
       "40171    2020-03-04\n",
       "40172    2020-11-30\n",
       "40173    2021-01-04\n",
       "40174    2021-03-09\n",
       "40175    2021-04-13\n",
       "Name: Start Date, Length: 40176, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_sql_query(query, engine)\n",
    "test['Start Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1965-01-12T00:00:00.000000000', '1965-01-12T00:00:00.000000000',\n",
       "       '1965-01-12T00:00:00.000000000', ...,\n",
       "       '1998-12-10T00:00:00.000000000', '1998-12-10T00:00:00.000000000',\n",
       "       '1998-12-10T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VERIFICATION\n",
    "\n",
    "query2= \"\"\"SELECT * FROM {0}.legacy_storet_temp WHERE \"Station\" in ('03339000')\n",
    "    \"\"\".format(project_name, \"','\".join(usgs_gages))\n",
    "\n",
    "test = pd.read_sql_query(query2, engine)\n",
    "dates = test['Start Date'].values\n",
    "dates.sort()\n",
    "dates\n",
    "#xxx = test[test['Station']=='03339000']['Start Date']\n",
    "#xxx.values.sort()\n",
    "#xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Station</th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Agency Name</th>\n",
       "      <th>State Name</th>\n",
       "      <th>County Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>End Date</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Sample Depth</th>\n",
       "      <th>UMK</th>\n",
       "      <th>Replicate Number</th>\n",
       "      <th>CS</th>\n",
       "      <th>COMPOSITE_GRAB_NUMBER</th>\n",
       "      <th>CM</th>\n",
       "      <th>Primary Activity Category</th>\n",
       "      <th>Secondary Activity Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [level_0, index, Agency, Station, Station Name, Agency Name, State Name, County Name, Latitude, Longitude, Result Value, R, HUC, Param, Start Date, Start Time, End Date, End Time, Sample Depth, UMK, Replicate Number, CS, COMPOSITE_GRAB_NUMBER, CM, Primary Activity Category, Secondary Activity Category]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VERIFICATION\n",
    "\n",
    "query3= \"\"\"SELECT * FROM {0}.legacy_storet_cleaned WHERE \"Station\" in ('03339000')\n",
    "    \"\"\".format(project_name, \"','\".join(usgs_gages))\n",
    "\n",
    "test = pd.read_sql_query(query3, engine)\n",
    "\n",
    "#dates = test['Start Date'].values\n",
    "#dates.sort()\n",
    "#dates\n",
    "#xxx = test[test['Station']=='03339000']['Start Date']\n",
    "#xxx.values.sort()\n",
    "#xxx\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete temporary table\n",
    "with engine.connect() as con:\n",
    "    con.execute(f\"\"\"DROP TABLE {project_name}.legacy_storet_temp;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xxx = pd.read_sql_table('legacy_storet_missing_test_v2',con=engine)\n",
    "#xxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the next section to 03_merge_legacy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
