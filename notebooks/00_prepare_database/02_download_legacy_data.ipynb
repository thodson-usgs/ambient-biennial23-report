{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build legacy storet database\n",
    "# Data accessed at https://www3.epa.gov/storet/legacy/gateway.htm\n",
    "#\n",
    "#result_file_list = glob.glob('C:/Users/thodson/Desktop/Projects/nrec/data/legacy_storet/Illinois/Illinois/*/*_res_*') \n",
    "#\n",
    "##build full database from legacy storet files\n",
    "#dtype = {\n",
    "#    'Start Time':str,\n",
    "#    'End Time': str,\n",
    "#    'Station': str,\n",
    "#    'Param': str,\n",
    "#    'HUC': str,\n",
    "#    'CS': str,\n",
    "#    'CM': str,\n",
    "#    'Primary Activity Category' : str,\n",
    "#    'Secondary Activity Category' : str\n",
    "#}\n",
    "#parse_dates = ['Start Date','End Date']\n",
    "#\n",
    "#for result_file in result_file_list:\n",
    "#    df = pd.read_csv(result_file,\n",
    "#                 sep='[ ]*\\t+[ ]*',\n",
    "#                 dtype=dtype,\n",
    "#                 parse_dates=parse_dates,\n",
    "#                 header=0, skiprows=[1])\n",
    "#    # drop all non-numeric results\n",
    "#    df['Result Value'] = pd.to_numeric(df['Result Value'], errors='coerce')\n",
    "#    df = df.dropna(subset=['Result Value', 'Start Date'])\n",
    "#    \n",
    "#    df.to_sql('legacy_storet',\n",
    "#              con=engine,\n",
    "#              schema='nrec',\n",
    "#              if_exists ='append')\n",
    "\n",
    "\n",
    "##df = pd.read_sql_table('legacy_storet',\n",
    "##                       con=engine,\n",
    "##                       schema='nrec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:Qwert213@localhost/postgres')\n",
    "\n",
    "project_name = 'ambient_2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Scroll down to crosswalk section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#0 load site info from excel table\n",
    "\n",
    "filename='../data/ambient_sites_v2023.csv'\n",
    "sites = pd.read_csv(filename, dtype={'USGS Code':str, 'USGS Gage':str})\n",
    "\n",
    "storet_id = 'IL_EPA_WQX-' + sites['StationCode']\n",
    "\n",
    "usgs_sites = sites['USGS Code']\n",
    "#usgs_sites = usgs_sites[usgs_sites.values != 'nan'].values.tolist()\n",
    "usgs_sites = usgs_sites[~usgs_sites.isna()].values.tolist()\n",
    "\n",
    "usgs_gages = sites['USGS Gage']\n",
    "#usgs_sites = usgs_sites[usgs_sites.values != 'nan'].values.tolist()\n",
    "usgs_gages = usgs_gages[~usgs_gages.isna()].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start here XXX\n",
    "gage_rename = sites[['USGS Code','USGS Gage']].dropna()\n",
    "usgs_sites = gage_rename['USGS Code']\n",
    "usgs_gages = gage_rename['USGS Gage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_with_different_gages_index = gage_rename['USGS Code'] != gage_rename['USGS Gage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['05563800',\n",
       " '05568005',\n",
       " '05577505',\n",
       " '03346550',\n",
       " '03343395',\n",
       " '03381495',\n",
       " '05554490',\n",
       " '05599500',\n",
       " '05593010',\n",
       " '05546700',\n",
       " '05553000']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usgs_sites[sites_with_different_gages_index].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all samples associated with sites (where site number differs from gage number)\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}') AND \"Agency\" = '21ILAMB'\n",
    "\"\"\".format(project_name, \"','\".join(usgs_sites[sites_with_different_gages_index].to_list()))\n",
    "\n",
    "samples_by_usgs_site = pd.read_sql_query(query, engine)\n",
    "# move samples to gage\n",
    "\n",
    "samples_by_usgs_site = samples_by_usgs_site.merge(gage_rename, how='inner', right_on='USGS Code', left_on='Station') \n",
    "samples_by_usgs_site['Station'] = samples_by_usgs_site['USGS Gage']\n",
    "samples_by_usgs_site = samples_by_usgs_site.drop(['USGS Gage','USGS Code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123433, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_site.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all samples by usgs gage ID\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}') AND \"Agency\" = '21ILAMB'\n",
    "\"\"\".format(project_name, \"','\".join(usgs_gages))\n",
    "\n",
    "samples_by_usgs_gage = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(894323, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_gage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#samples_by_usgs_gage = samples_by_usgs_gage.append(samples_by_usgs_site)\n",
    "samples_by_usgs_gage = pd.concat([samples_by_usgs_gage, samples_by_usgs_site])\n",
    "samples_by_usgs_gage = samples_by_usgs_gage.replace({'00940':'99220'})\n",
    "samples_by_usgs_gage.to_sql('legacy_storet_temp',\n",
    "            con=engine,\n",
    "            schema=project_name,\n",
    "            if_exists ='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017756, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_gage.shape\n",
    "#append\n",
    "# drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thodson\\AppData\\Local\\Temp\\1\\ipykernel_10736\\3078081650.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  station_rename = station_rename.append(other_legacy_sites)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select mislabeld samples and append to legacy_storet_temp XXX\n",
    "station_rename = sites[['StationCode','USGS Gage']].dropna()\n",
    "station_rename['StationCode'] = station_rename['StationCode'].str.replace('-',' ')\n",
    "\n",
    "other_legacy_sites = [\n",
    "    ['DT      01', '05552500']\n",
    "]\n",
    "other_legacy_sites = pd.DataFrame(other_legacy_sites, columns=['StationCode','USGS Gage'])\n",
    "\n",
    "station_rename = station_rename.append(other_legacy_sites)\n",
    "\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}')\n",
    "\"\"\".format(project_name, \"','\".join(station_rename['StationCode'].to_list()))\n",
    "\n",
    "missing_samples = pd.read_sql_query(query, engine)\n",
    "missing_samples = missing_samples.replace({'00940':'99220'})\n",
    "# rename Stations to match USGS gages\n",
    "station_rename_dict = {row['StationCode']:row['USGS Gage'] for index, row in station_rename.iterrows()}\n",
    "missing_samples['Station'] = missing_samples['Station'].replace(station_rename_dict)\n",
    "\n",
    "missing_samples.to_sql('legacy_storet_temp',\n",
    "            con=engine,\n",
    "            schema=project_name,\n",
    "            if_exists ='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 24)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_samples.shape #was 1679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1027031, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx = pd.read_sql_table('legacy_storet_temp',con=engine, schema='nrec')\n",
    "xxx.shape #was (1027031, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do the above for each parameter in parameter list and append\n",
    "#query = \"\"\"\n",
    "#SELECT site_no as \"Station\", sample_dt as \"Start Date\" FROM nrec.wrtds WHERE p{0} IS NOT NULL\n",
    "#AND site_no in ('{1}')\n",
    "#\"\"\".format(parameter,\n",
    "#           \"','\".join(usgs_sites))\n",
    "\n",
    "\n",
    "\n",
    "param_list = ['00530','00535','00600','00610','00625','00630','00665','00666','00667', '00946', '80154','99220']\n",
    "#param_list = ['00535']\n",
    "\n",
    "for parameter in param_list:\n",
    "    # select samples wrtds where site_no is in list of usgs gages\n",
    "    #SELECT site_no as \"Station\", TO_TIMESTAMP(sample_dt, 'YYYY-MM-DD') AT TIME ZONE 'CST' as \"Start Date\" FROM nrec.wrtds WHERE p{0} IS NOT NULL \n",
    "    query = \"\"\"\n",
    "    SELECT site_no as \"Station\", TO_DATE(cast(sample_dt as TEXT), 'YYYY-MM-DD') as \"Start Date\" FROM {0}.wrtds WHERE p{1} IS NOT NULL    \n",
    "    AND site_no in ('{2}')\n",
    "    \"\"\".format(project_name, parameter,\n",
    "               \"','\".join(usgs_gages)) #20210628 changed from usgs_sites\n",
    "    \n",
    "    # select samples form legacy storet where station in list of \n",
    "    query2 = \"\"\"SELECT * FROM {0}.legacy_storet_temp WHERE \"Station\" in ('{1}')\n",
    "    AND \"Param\" in ('{2}') AND \"Agency\" = '21ILAMB'\n",
    "    \"\"\".format(project_name, \"','\".join(usgs_gages),\n",
    "               parameter)\n",
    "    \n",
    "    query3 = \"\"\"\n",
    "    SELECT * FROM ({}) as table1\n",
    "    WHERE (\"Station\",\"Start Date\")\n",
    "    NOT IN ({})\n",
    "    \"\"\".format(query2, query)\n",
    "    \n",
    "\n",
    "    df = pd.read_sql_query(query3, engine)\n",
    "    \n",
    "    #df.to_sql('legacy_storet_missing_test',\n",
    "    df.to_sql('legacy_storet_cleaned',\n",
    "              con=engine,\n",
    "              schema=project_name,\n",
    "              if_exists ='append')\n",
    "\n",
    "# check in pg admin\n",
    "# select \"Start Date\" FROM nrec.legacy_storet_missing_test_v2 WHERE \"Station\"='05568000' AND \"Param\"='00630' ORDER BY \"Start Date\" DESC;\n",
    "\n",
    "# delete temporary table\n",
    "with engine.connect() as con:\n",
    "    con.execute(f\"\"\"DROP TABLE {project_name}.legacy_storet_temp;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xxx = pd.read_sql_table('legacy_storet_missing_test_v2',con=engine)\n",
    "#xxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the next section to 03_merge_legacy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
