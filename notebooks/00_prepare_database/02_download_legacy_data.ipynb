{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build legacy storet database\n",
    "# Data accessed at https://www3.epa.gov/storet/legacy/gateway.htm\n",
    "#\n",
    "#result_file_list = glob.glob('C:/Users/thodson/Desktop/Projects/nrec/data/legacy_storet/Illinois/Illinois/*/*_res_*') \n",
    "#\n",
    "##build full database from legacy storet files\n",
    "#dtype = {\n",
    "#    'Start Time':str,\n",
    "#    'End Time': str,\n",
    "#    'Station': str,\n",
    "#    'Param': str,\n",
    "#    'HUC': str,\n",
    "#    'CS': str,\n",
    "#    'CM': str,\n",
    "#    'Primary Activity Category' : str,\n",
    "#    'Secondary Activity Category' : str\n",
    "#}\n",
    "#parse_dates = ['Start Date','End Date']\n",
    "#\n",
    "#for result_file in result_file_list:\n",
    "#    df = pd.read_csv(result_file,\n",
    "#                 sep='[ ]*\\t+[ ]*',\n",
    "#                 dtype=dtype,\n",
    "#                 parse_dates=parse_dates,\n",
    "#                 header=0, skiprows=[1])\n",
    "#    # drop all non-numeric results\n",
    "#    df['Result Value'] = pd.to_numeric(df['Result Value'], errors='coerce')\n",
    "#    df = df.dropna(subset=['Result Value', 'Start Date'])\n",
    "#    \n",
    "#    df.to_sql('legacy_storet',\n",
    "#              con=engine,\n",
    "#              schema='nrec',\n",
    "#              if_exists ='append')\n",
    "\n",
    "\n",
    "##df = pd.read_sql_table('legacy_storet',\n",
    "##                       con=engine,\n",
    "##                       schema='nrec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:Qwert213@localhost/postgres')\n",
    "\n",
    "project_name = 'ambient_2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Scroll down to crosswalk section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#0 load site info from excel table\n",
    "\n",
    "filename='../../data/ambient_sites_v2023.csv'\n",
    "sites = pd.read_csv(filename, dtype={'USGS Code':str, 'USGS Gage':str})\n",
    "\n",
    "storet_id = 'IL_EPA_WQX-' + sites['StationCode']\n",
    "\n",
    "usgs_sites = sites['USGS Code']\n",
    "#usgs_sites = usgs_sites[usgs_sites.values != 'nan'].values.tolist()\n",
    "usgs_sites = usgs_sites[~usgs_sites.isna()].values.tolist()\n",
    "\n",
    "usgs_gages = sites['USGS Gage']\n",
    "#usgs_sites = usgs_sites[usgs_sites.values != 'nan'].values.tolist()\n",
    "usgs_gages = usgs_gages[~usgs_gages.isna()].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start here XXX\n",
    "gage_rename = sites[['USGS Code','USGS Gage']].dropna()\n",
    "usgs_sites = gage_rename['USGS Code']\n",
    "usgs_gages = gage_rename['USGS Gage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_with_different_gages_index = gage_rename['USGS Code'] != gage_rename['USGS Gage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['05568005',\n",
       " '05577505',\n",
       " '03346550',\n",
       " '03343395',\n",
       " '03381495',\n",
       " '05554490',\n",
       " '05599500',\n",
       " '05593010',\n",
       " '05546700',\n",
       " '05553000']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usgs_sites[sites_with_different_gages_index].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all samples associated with sites (where site number differs from gage number)\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}') AND \"Agency\" = '21ILAMB'\n",
    "\"\"\".format(project_name, \"','\".join(usgs_sites[sites_with_different_gages_index].to_list()))\n",
    "\n",
    "samples_by_usgs_site = pd.read_sql_query(query, engine)\n",
    "# move samples to gage\n",
    "\n",
    "samples_by_usgs_site = samples_by_usgs_site.merge(gage_rename, how='inner', right_on='USGS Code', left_on='Station') \n",
    "samples_by_usgs_site['Station'] = samples_by_usgs_site['USGS Gage']\n",
    "samples_by_usgs_site = samples_by_usgs_site.drop(['USGS Gage','USGS Code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110247, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_site.shape #123433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all samples by usgs gage ID\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}') AND \"Agency\" = '21ILAMB'\n",
    "\"\"\".format(project_name, \"','\".join(usgs_gages))\n",
    "\n",
    "samples_by_usgs_gage = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(907509, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_gage.shape #894323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#samples_by_usgs_gage = samples_by_usgs_gage.append(samples_by_usgs_site)\n",
    "samples_by_usgs_gage = pd.concat([samples_by_usgs_gage, samples_by_usgs_site])\n",
    "samples_by_usgs_gage = samples_by_usgs_gage.replace({'00940':'99220'})\n",
    "samples_by_usgs_gage.to_sql('legacy_storet_temp',\n",
    "            con=engine,\n",
    "            schema=project_name,\n",
    "            if_exists ='replace')\n",
    "#756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017756, 24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_by_usgs_gage.shape #1017756\n",
    "#append\n",
    "# drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thodson\\AppData\\Local\\Temp\\2\\ipykernel_30332\\4046451299.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  station_rename = station_rename.append(other_legacy_sites)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select mislabeld samples and append to legacy_storet_temp XXX\n",
    "station_rename = sites[['StationCode','USGS Gage']].dropna()\n",
    "station_rename['StationCode'] = station_rename['StationCode'].str.replace('-',' ')\n",
    "\n",
    "other_legacy_sites = [\n",
    "    ['DT      01', '05552500']\n",
    "]\n",
    "other_legacy_sites = pd.DataFrame(other_legacy_sites, columns=['StationCode','USGS Gage'])\n",
    "\n",
    "station_rename = station_rename.append(other_legacy_sites)\n",
    "\n",
    "query = \"\"\"SELECT * FROM {}.legacy_storet WHERE \"Station\" in ('{}')\n",
    "\"\"\".format(project_name, \"','\".join(station_rename['StationCode'].to_list()))\n",
    "\n",
    "missing_samples = pd.read_sql_query(query, engine)\n",
    "missing_samples = missing_samples.replace({'00940':'99220'})\n",
    "# rename Stations to match USGS gages\n",
    "station_rename_dict = {row['StationCode']:row['USGS Gage'] for index, row in station_rename.iterrows()}\n",
    "missing_samples['Station'] = missing_samples['Station'].replace(station_rename_dict)\n",
    "\n",
    "missing_samples.to_sql('legacy_storet_temp',\n",
    "            con=engine,\n",
    "            schema=project_name,\n",
    "            if_exists ='append')\n",
    "\n",
    "#679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 24)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_samples.shape #1679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019435, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx = pd.read_sql_table('legacy_storet_temp',con=engine, schema='ambient_2023') # was nrec\n",
    "xxx.shape #was (1027031\n",
    "#1019435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767026   1965-01-12\n",
       "767027   1965-01-12\n",
       "767028   1965-01-12\n",
       "767029   1965-12-10\n",
       "767030   1965-12-10\n",
       "            ...    \n",
       "804701   1998-12-10\n",
       "804702   1998-12-10\n",
       "804703   1998-12-10\n",
       "804704   1998-12-10\n",
       "804705   1998-12-10\n",
       "Name: Start Date, Length: 13707, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify legacy_storet_temp\n",
    "test = xxx[xxx['Station'] == '03339000']['Start Date']\n",
    "test.values.sort()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ambient_2023'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01003', '01052', '01053', '01068', '32211', '32212', '32214',\n",
       "       '39350', '39351', '39356', '39359', '00116', '00339', '01008',\n",
       "       '01043', '01078', '01170', '32210', '39076', '39111', '39300',\n",
       "       '39301', '39305', '39306', '00627', '00668', '00938', '01028',\n",
       "       '01029', '01093', '32218', '39032', '39062', '39064', '39370',\n",
       "       '39380', '39383', '39310', '39311', '39315', '39316', '39320',\n",
       "       '39321', '39327', '39328', '39330', '39333', '39337', '39340',\n",
       "       '39343', '39390', '39393', '39413', '39423', '39480', '39481',\n",
       "       '71921', '81284', '81294', '81403', '81408', '81410', '81757',\n",
       "       '82088', '39519', '39701', '39783', '70322', '39065', '39067',\n",
       "       '39070', '39073', '39516', '39530', '39570', '39600', '39630',\n",
       "       '39640', '39700', '77825', '46313', '00010', '00020', '00301',\n",
       "       '00610', '00612', '00619', '00299', '00400', '00625', '00027',\n",
       "       '00028', '00076', '00094', '00410', '00530', '00535', '00666',\n",
       "       '00720', '99220', '00945', '00951', '01002', '01030', '01034',\n",
       "       '01035', '00900', '00929', '00930', '00935', '00937', '01020',\n",
       "       '01022', '01025', '01027', '01040', '00630', '00665', '00915',\n",
       "       '00916', '00925', '00927', '01005', '01007', '01010', '01037',\n",
       "       '01065', '01067', '01075', '01077', '01080', '31616', '32730',\n",
       "       '46570', '01042', '01045', '01046', '01082', '01085', '01087',\n",
       "       '01090', '01092', '71900', '01012', '01049', '01051', '01055',\n",
       "       '01056', '01105', '01106', '01147', '46489'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_samples['Param'].unique()\n",
    "#missing_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existing table\n",
    "with engine.connect() as con:\n",
    "    con.execute(f\"\"\"DROP TABLE {project_name}.legacy_storet_cleaned;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do the above for each parameter in parameter list and append\n",
    "#query = \"\"\"\n",
    "#SELECT site_no as \"Station\", sample_dt as \"Start Date\" FROM nrec.wrtds WHERE p{0} IS NOT NULL\n",
    "#AND site_no in ('{1}')\n",
    "#\"\"\".format(parameter,\n",
    "#           \"','\".join(usgs_sites))\n",
    "\n",
    "# list must contain entries in the cleaned qwdata table. Cleaning moves 631 to 630; 631 doesn't appear in my legacy\n",
    "param_list = ['00530','00535','00600','00610','00625','00630','00665','00666','00667', '00946', '80154','99220','01045','01046']\n",
    "#param_list = ['00665']\n",
    "\n",
    "for parameter in param_list:\n",
    "    # select samples wrtds where site_no is in list of usgs gages\n",
    "    #SELECT site_no as \"Station\", TO_TIMESTAMP(sample_dt, 'YYYY-MM-DD') AT TIME ZONE 'CST' as \"Start Date\" FROM nrec.wrtds WHERE p{0} IS NOT NULL \n",
    "    query = \"\"\"\n",
    "    SELECT site_no as \"Station\", TO_DATE(cast(sample_dt as TEXT), 'YYYY-MM-DD') as \"Start Date\" FROM {0}.wrtds WHERE p{1} IS NOT NULL    \n",
    "    AND site_no in ('{2}')\n",
    "    \"\"\".format(project_name, parameter,\n",
    "               \"','\".join(usgs_gages)) #20210628 changed from usgs_sites\n",
    "    \n",
    "    # select samples form legacy storet where station in list of \n",
    "    query2 = \"\"\"SELECT * FROM {0}.legacy_storet_temp WHERE \"Station\" in ('{1}')\n",
    "    AND \"Param\" in ('{2}') AND \"Agency\" = '21ILAMB'\n",
    "    \"\"\".format(project_name, \"','\".join(usgs_gages),\n",
    "               parameter)\n",
    "    \n",
    "    query3 = \"\"\"\n",
    "    SELECT * FROM ({}) as table1\n",
    "    WHERE (\"Station\",\"Start Date\")\n",
    "    NOT IN ({})\n",
    "    \"\"\".format(query2, query)\n",
    "    \n",
    "\n",
    "    df = pd.read_sql_query(query3, engine)\n",
    "    \n",
    "    #df.to_sql('legacy_storet_missing_test',\n",
    "    # append each parameter to list\n",
    "    df.to_sql('legacy_storet_cleaned',\n",
    "              con=engine,\n",
    "              schema=project_name,\n",
    "              if_exists='append')\n",
    "\n",
    "# check in pg admin\n",
    "# select \"Start Date\" FROM nrec.legacy_storet_missing_test_v2 WHERE \"Station\"='05568000' AND \"Param\"='00630' ORDER BY \"Start Date\" DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete temporary table\n",
    "with engine.connect() as con:\n",
    "    con.execute(f\"\"\"DROP TABLE {project_name}.legacy_storet_temp;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
